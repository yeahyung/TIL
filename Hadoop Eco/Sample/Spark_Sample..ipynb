{
  "metadata": {
    "name": "Spark_Sample",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nspark.sql(\"show tables\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval df \u003d spark.sql(\"select * from my_table\")\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nspark.sql(\"select * from movies\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval df \u003d spark.table(\"movies\")\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nshow tables;\ndescribe table movies;"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport spark.implicits._\nimport org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.catalyst.ScalaReflection\n\ncase class Movie(movieId: Int, title: String, genres: String)\nval movies_schema \u003d ScalaReflection.schemaFor[Movie].dataType.asInstanceOf[StructType]  // create schema from case class"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval movie_df_temp \u003d spark.read\n        .option(\"header\", \"true\")\n        .schema(movies_schema)\n        .csv(\"hdfs://catalog-test/user/root/movie.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types.IntegerType\n\nval movie_df \u003d movie_df_temp\n    .select($\"movieId\", $\"title\", explode(split($\"genres\", \"\\\\|\")).as(\"genre\"))\n    .withColumn(\"releasedYear\", regexp_extract($\"title\", \"\\\\((\\\\d{4})\\\\)\", 1))\n    .withColumn(\"releasedYear\", $\"releasedYear\".cast(IntegerType))"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nmovie_df.createOrReplaceTempView(\"movie\")\nspark.sql(\"show tables\").show()\nspark.sql(\"desc movie\").show()\nspark.sql(\"select * from movie limit 3\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// rating.csv\nimport spark.implicits._\nimport org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.catalyst.ScalaReflection\nimport java.sql.Timestamp\nimport org.apache.spark.sql.functions._\n\ncase class Rating(userId: Int, movieId: Int, rating: Double, timestamp: Timestamp)\nval rating_schema \u003d ScalaReflection.schemaFor[Rating].dataType.asInstanceOf[StructType]\nval rating_df_temp \u003d spark.read\n    .option(\"header\", \"true\")\n    .schema(rating_schema)\n    .csv(\"hdfs://catalog-test/user/root/rating.csv\")\n\nval rating_df_filtered \u003d rating_df_temp.groupBy($\"movieId\")\n    .agg(count(\"*\").as(\"count\")).filter($\"count\" \u003e 10) // Filter out recored where only few people rate the movie\nval rating_df \u003d rating_df_temp.join(rating_df_filtered, rating_df_temp(\"movieId\") \u003d\u003d\u003d rating_df_filtered(\"movieId\"))\n    .select($\"userId\", rating_df_temp(\"movieId\"), $\"rating\", year($\"timestamp\").as(\"year\"), month($\"timestamp\").as(\"month\"))\n    \nrating_df.createOrReplaceTempView(\"rating\")\nspark.sql(\"select * from rating limit 3\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Find out top rated movies\nspark.sql(\"select movieId, avg(rating) as avgRating from rating group by movieId order by avgRating desc limit 5\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Find out top rated genres\nspark.sql(\"select m.genre, avg(r.rating) as avgRating from movie m join rating r on m.movieId \u003d r.movieId group by m.genre order by avgRating desc limit 5\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// Create a new dataframe by joining\n// Use Seq in order to avoid having duplicated column\nval movie_rating_df \u003d movie_df.join(rating_df, Seq(\"movieId\"), \"inner\")\nmovie_rating_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n// 새로운 dataframe을 parquet으로 저장(year, month partition 지정)\nimport org.apache.spark.sql.SaveMode\nmovie_rating_df.repartition($\"year\", $\"month\")\n    .write.partitionBy(\"year\", \"month\")\n    .mode(SaveMode.Append)\n    .parquet(\"hdfs://catalog-test/user/root/movie_rating\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%jdbc(hive)\nCREATE DATABASE example__db_movie_rating\nCOMMENT \u0027MovieLens 20M Dataset\u0027\nLocation \u0027hdfs://catalog-test/user/hadoop-test/example__db_movig_rating\u0027;\n\nSHOW DATABASES;\n\nDESCRIBE DATABASE example__db_movie_rating;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%jdbc(hive)\nUSE example__db_movie_rating;\n\nCREATE EXTERNAL TABLE movie_rating (movieId int, title string, genre string, releasedYear int, userId int, rating double)\npartitioned by (year int, month int) stored as parquet\nlocation \u0027hdfs://catalog-test/user/root/movie_rating\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%jdbc(hive)\n// partition 추가 및 메타데이터 업데이트\nMSCK REPAIR TABLE movie_rating;\n\nSHOW TABLES;\n\nDESCRIBE movie_rating;\n\nSELECT * FROM movie_rating limit 3;"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%jdbc(hive)\nSELECT releasedYear, title, avgRating, row_num\nFROM (SELECT releasedYear, title, avg(rating) as avgRating, rank() over (partition by releasedYear order by avg(rating) desc) as row_num\nFROM movie_rating GROUP BY releasedYear, title) T\nwhere row_num \u003c\u003d 3 ORDER BY releasedYear, row_num;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%jdbc(hive)\nSELECT year, title, popularity, row_num FROM\n(SELECT year, title, count(distinct userID) as popularity, rank() over (partition by year order by count(distinct userID) desc) as row_num\nFROM movie_rating GROUP BY year, title) T\nWHERE row_num \u003d 1 ORDER BY year, popularity desc;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nspark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// ETL Sample Code\n\nimport spark.implicits._\nimport org.apache.spark.sql.types.StructType\nimport org.apache.spark.sql.catalyst.ScalaReflection\n\ncase class Movie(movieId: Int, title: String, genres: String)\nval movies_schema \u003d ScalaReflection.schemaFor[Movie].dataType.asInstanceOf[StructType]  // create schema from case class\n\n// Read Source Data(Extract)\nval movie_df \u003d spark.read\n        .option(\"header\", \"true\")\n        .schema(movies_schema)\n        .csv(\"hdfs://catalog-test/user/root/movie.csv\")\n        \nmovie_df.show()\n        \n// Transformation\nval transformedDf \u003d movie_df\n    .select($\"movieId\", $\"title\", explode(split($\"genres\", \"\\\\|\")).as(\"genre\"))\n    .withColumn(\"releasedYear\", regexp_extract($\"title\", \"\\\\((\\\\d{4})\\\\)\", 1))\n    .withColumn(\"releasedYear\", $\"releasedYear\".cast(IntegerType))\n    \ntransformedDf.show()\n\n// Write transformed data to target location(Load)\ntransformedDf.write.format(\"csv\")\n    .option(\"header\", \"true\")\n    .save(\"hdfs://catalog-test/user/root/movie_transformed.csv\")"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval read_transformed_df \u003d spark.read\n    .format(\"csv\")\n    .option(\"header\", \"true\")\n    .option(\"inferSchema\", \"true\")\n    .load(\"hdfs://catalog-test/user/root/movie_transformed.csv\")\n    \nread_transformed_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n\n// ETL Sample Code using Hive\n\n// Read in the source data from a Hive table\n// Spark 에서 Hive Table 읽을 경우, first column 이 포함됨(skip.header.line.count 을 인식하지 못함), 따라서 따로 전처리 필요\n//val movie_df_temp \u003d spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").format(\"csv\").load(\"hdfs://catalog-test/user/root/movie.csv\") header 무시해서 읽음\nval movie_df_temp \u003d spark.table(\"movies\") // hive 에서 바로 읽음\n\n//movie_df_temp.show()\n\n// Filter out first row\nval movie_df \u003d movie_df_temp.filter(movie_df_temp(\"movieid\") \u003d!\u003d 0)\nmovie_df.show()\n\n\n// Transformation\nval transformedDF \u003d movie_df\n    .select($\"movieId\", $\"title\", explode(split($\"genres\", \"\\\\|\")).as(\"genre\"))\n    .withColumn(\"releasedYear\", regexp_extract($\"title\", \"\\\\((\\\\d{4})\\\\)\", 1))\n    .withColumn(\"releasedYear\", $\"releasedYear\".cast(IntegerType))\ntransformedDF.show()\n\n// Write the transformed data to a new Hive table\ntransformedDF.write\n    .format(\"hive\")\n    .mode(\"overwrite\")\n    .option(\"path\", \"hdfs://catalog-test/user/root/transformed_movie.csv\")\n    .saveAsTable(\"transformed_movie\")"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    }
  ]
}